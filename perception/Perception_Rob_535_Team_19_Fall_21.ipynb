{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QWFCBObeUsx"
      },
      "source": [
        "Installation of requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oj4cQGALd-je",
        "outputId": "aa47a002-3879-4f2c-9931-c3f6e4448ac9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'ls' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\alex\\anaconda3\\lib\\site-packages (1.10.0)\n",
            "Requirement already satisfied: torchvision in c:\\users\\alex\\anaconda3\\lib\\site-packages (0.11.1)\n",
            "Requirement already satisfied: typing_extensions in c:\\users\\alex\\anaconda3\\lib\\site-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in c:\\users\\alex\\anaconda3\\lib\\site-packages (from torchvision) (1.20.1)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from torchvision) (8.2.0)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\alex\\anaconda3\\lib\\site-packages (3.3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.15 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib) (1.20.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib) (8.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: six in c:\\users\\alex\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Collecting pyyaml==5.1\n",
            "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Building wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py): started\n",
            "  Building wheel for pyyaml (setup.py): finished with status 'done'\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1-cp38-cp38-win_amd64.whl size=44070 sha256=5a4786a604845d3f6e180a66e850ddde8d00d43d2e3df59536ffe23ac84f511e\n",
            "  Stored in directory: c:\\users\\alex\\appdata\\local\\pip\\cache\\wheels\\52\\dd\\2b\\10ff8b0ac81b93946bb5fb9e6749bae2dac246506c8774e6cf\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 5.4.1\n",
            "    Uninstalling PyYAML-5.4.1:\n",
            "      Successfully uninstalled PyYAML-5.4.1\n",
            "Successfully installed pyyaml-5.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in c:\\users\\alex\\anaconda3\\lib\\site-packages (3.3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib) (1.20.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib) (8.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: six in c:\\users\\alex\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: pillow in c:\\users\\alex\\anaconda3\\lib\\site-packages (8.2.0)\n"
          ]
        }
      ],
      "source": [
        "!ls\n",
        "!pip3 install torch torchvision\n",
        "!pip3 install matplotlib\n",
        "!pip install pyyaml==5.1\n",
        "!pip3 install matplotlib\n",
        "!pip3 install pillow\n",
        "#!unzip ./drive/MyDrive/deploy.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODSABHvweMRK"
      },
      "source": [
        "Dataloader for the GTA Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "15q0KqcfPSoN"
      },
      "outputs": [],
      "source": [
        "deploy_dir = \".\"\n",
        "model_save_dir = \".models/\"\n",
        "\n",
        "\"\"\"\n",
        "    Dataloaders for training and testing.\n",
        "    Import the function readTrImages and MyDataset object for creating the training and validation dataloaders.\n",
        "    Important!! - Make sure the deploy folder is in the same directory as this loader file. \n",
        "    TODO: Make testing code.       \n",
        "\"\"\"\n",
        "import sys\n",
        "import os\n",
        "import struct\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import random\n",
        "from numpy.lib.shape_base import split\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from matplotlib.pyplot import imshow\n",
        "from matplotlib import cm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "classes = (\n",
        "    'Unknown', 'Compacts', 'Sedans', 'SUVs', 'Coupes',\n",
        "    'Muscle', 'SportsClassics', 'Sports', 'Super', 'Motorcycles',\n",
        "    'OffRoad', 'Industrial', 'Utility', 'Vans', 'Cycles',\n",
        "    'Boats', 'Helicopters', 'Planes', 'Service', 'Emergency',\n",
        "    'Military', 'Commercial', 'Trains'\n",
        ")\n",
        "classes_to_labels = {\n",
        "    'Unknown':0, 'Compacts':1, 'Sedans':1, 'SUVs':1, 'Coupes':1,\n",
        "    'Muscle':1, 'SportsClassics':1, 'Sports':1, 'Super':1, 'Motorcycles':2,\n",
        "    'OffRoad':2, 'Industrial':2, 'Utility':2, 'Vans':2, 'Cycles':2,\n",
        "    'Boats':0, 'Helicopters':0, 'Planes':0, 'Service':0, 'Emergency':0,\n",
        "    'Military':0, 'Commercial':0, 'Trains':0\n",
        "}\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    # An object for representing the Dataset for Pytorch.\n",
        "    def __init__(self, image_fns, labels, dim):\n",
        "        super().__init__()\n",
        "        self.image_fns = image_fns\n",
        "        self.image_orig_shape = None\n",
        "        self.labels = labels\n",
        "        if not dim:\n",
        "            self.dim = False\n",
        "        else:\n",
        "            self.dim = dim\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(len(self.image_fns), len(self.labels))\n",
        "\n",
        "    def getImage(self, index):\n",
        "        image = Image.open(self.image_fns[index])\n",
        "        self.image_orig_shape = image.size\n",
        "        convert_tensor = transforms.ToTensor()\n",
        "        image = torch.tensor(convert_tensor(image), requires_grad=True, device=device)\n",
        "        image = F.interpolate(image, size=self.dim) \n",
        "        return image\n",
        "    \n",
        "    def getMask(self, index):\n",
        "        #cols,rows = self.image_orig_shape\n",
        "        bb = self.labels[index][0][1]\n",
        "        label = self.labels[index][0][0][0]\n",
        "        label = classes_to_labels[label]\n",
        "        #Y = np.zeros((rows, cols))\n",
        "        bb = np.array(bb)\n",
        "        bb = bb.astype(np.int)\n",
        "        #Y[bb[0]:bb[1], bb[1]:bb[2]] = 1.\n",
        "        bb = torch.tensor([bb[2], bb[0], bb[3], bb[1]], dtype=torch.long, device=device)\n",
        "        #mask = Image.fromarray(np.uint8(cm.gist_earth(Y)*255))\n",
        "        #if self.dim:\n",
        "            #mask = mask.resize((self.dim, self.dim))\n",
        "        convert_tensor = transforms.ToTensor()\n",
        "        #mask = torch.tensor(convert_tensor(mask), requires_grad=True, device=device)\n",
        "        label = torch.tensor(label, dtype=torch.long, device=device)\n",
        "        label = F.one_hot(label, num_classes=3)\n",
        "        return label, bb\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.getImage(index)\n",
        "        label, bb = self.getMask(index)\n",
        "        target = {}\n",
        "        target[\"boxes\"] = bb\n",
        "        target[\"labels\"] = label\n",
        "        #target[\"masks\"] = mask\n",
        "        return image, target\n",
        "\n",
        "def writeFirstSubmission():\n",
        "    # The code for the first submission.\n",
        "    output = open('Team19.txt', 'w')\n",
        "    output.write('guid/image,label\\n')\n",
        "    count = 0\n",
        "\n",
        "    for folder in os.listdir(deploy_dir + '/deploy/test/'):\n",
        "        for file in os.listdir(deploy_dir + '/deploy/test/' + folder):\n",
        "            if file.endswith(\"_image.jpg\"):\n",
        "                output.write(folder + \"/\" + file[:-10] + \",1\\n\")\n",
        "                count += 1\n",
        "\n",
        "    print(count)\n",
        "    output.close()\n",
        "    \n",
        "def readTrLabels(train=False):\n",
        "    # Reading the training labels from the generated trainval_labels.csv file, which is generated by extract_info.py from Canvas.\n",
        "    file_to_read = deploy_dir + \"deploy/trainval/trainval_labels.csv\"\n",
        "    label_dict = {}\n",
        "    file_data = open(file_to_read)\n",
        "    count = 0\n",
        "    for row in file_data:\n",
        "        if count != 0:\n",
        "            split_lst = row.split(',')\n",
        "            label_dict[split_lst[0]] = int(split_lst[1][0])\n",
        "        count += 1\n",
        "    return label_dict\n",
        "\n",
        "def rot(n):\n",
        "    n = np.asarray(n).flatten()\n",
        "    assert(n.size == 3)\n",
        "\n",
        "    theta = np.linalg.norm(n)\n",
        "    if theta:\n",
        "        n /= theta\n",
        "        K = np.array([[0, -n[2], n[1]], [n[2], 0, -n[0]], [-n[1], n[0], 0]])\n",
        "\n",
        "        return np.identity(3) + np.sin(theta) * K + (1 - np.cos(theta)) * K @ K\n",
        "    else:\n",
        "        return np.identity(3)\n",
        "\n",
        "def get_bbox(p0, p1):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "    *   p0, p1\n",
        "        (3)\n",
        "        Corners of a bounding box represented in the body frame.\n",
        "\n",
        "    Output:\n",
        "    *   v\n",
        "        (3, 8)\n",
        "        Vertices of the bounding box represented in the body frame.\n",
        "    *   e\n",
        "        (2, 14)\n",
        "        Edges of the bounding box. The first 2 edges indicate the `front` side\n",
        "        of the box.\n",
        "    \"\"\"\n",
        "    v = np.array([\n",
        "        [p0[0], p0[0], p0[0], p0[0], p1[0], p1[0], p1[0], p1[0]],\n",
        "        [p0[1], p0[1], p1[1], p1[1], p0[1], p0[1], p1[1], p1[1]],\n",
        "        [p0[2], p1[2], p0[2], p1[2], p0[2], p1[2], p0[2], p1[2]]\n",
        "    ])\n",
        "    e = np.array([\n",
        "        [2, 3, 0, 0, 3, 3, 0, 1, 2, 3, 4, 4, 7, 7],\n",
        "        [7, 6, 1, 2, 1, 2, 4, 5, 6, 7, 5, 6, 5, 6]\n",
        "    ], dtype=np.uint8)\n",
        "\n",
        "    return v, e\n",
        "\n",
        "def readBbox(snapshot):\n",
        "    xyz = np.fromfile(snapshot.replace('_image.jpg', '_cloud.bin'), dtype=np.float32)\n",
        "    xyz = xyz.reshape([3, -1])\n",
        "\n",
        "    proj = np.fromfile(snapshot.replace('_image.jpg', '_proj.bin'), dtype=np.float32)\n",
        "    proj.resize([3, 4])\n",
        "\n",
        "    try:\n",
        "        bbox = np.fromfile(snapshot.replace('_image.jpg', '_bbox.bin'), dtype=np.float32)\n",
        "    except FileNotFoundError:\n",
        "        print('[*] bbox not found.')\n",
        "        bbox = np.array([], dtype=np.float32)\n",
        "    \n",
        "    bbox = bbox.reshape([-1, 11])\n",
        "\n",
        "    uv = proj @ np.vstack([xyz, np.ones_like(xyz[0, :])])\n",
        "    uv = uv / uv[2, :]\n",
        "\n",
        "    bbox_list = []\n",
        "    \n",
        "    for k, b in enumerate(bbox):\n",
        "        R = rot(b[0:3])\n",
        "        t = b[3:6]\n",
        "\n",
        "        sz = b[6:9]\n",
        "        vert_3D, edges = get_bbox(-sz / 2, sz / 2)\n",
        "        vert_3D = R @ vert_3D + t[:, np.newaxis]\n",
        "\n",
        "        vert_2D = proj @ np.vstack([vert_3D, np.ones(vert_3D.shape[1])])\n",
        "        vert_2D = vert_2D / vert_2D[2, :]\n",
        "        min_x, min_y = 10000, 10000\n",
        "        max_x, max_y = -1000, -1000\n",
        "\n",
        "        for e in edges.T:\n",
        "            #print(vert_2D[0, e], vert_2D[1, e]) # 2D bbox\n",
        "            x1 = vert_2D[0, e][0]\n",
        "            x2 = vert_2D[0, e][1]\n",
        "            y1 = vert_2D[1, e][0]\n",
        "            y2 = vert_2D[1, e][1]\n",
        "\n",
        "            if y1 < min_y and y1 > 0:\n",
        "                min_y = int(y1)\n",
        "            if y1 > max_y:\n",
        "                max_y = int(y1)\n",
        "            if y2 < min_y and y2 > 0:\n",
        "                min_y = int(y2)\n",
        "            if y2 > max_y:\n",
        "                max_y = int(y2)\n",
        "\n",
        "            if x1 < min_x and x1 > 0:\n",
        "                min_x = int(x1)\n",
        "            if x1 > max_x:\n",
        "                max_x = int(x1)\n",
        "            if x2 < min_x:\n",
        "                min_x = int(x2)\n",
        "            if x2 > max_x:\n",
        "                max_x = int(x2)\n",
        "                       \n",
        "            #print(vert_3D[0, e], vert_3D[1, e], vert_3D[2, e]) # 3d bbox\n",
        "\n",
        "        c = classes[int(b[9])]\n",
        "        bbox_list.append([[c], [min_y, max_y, min_x, max_x]])\n",
        "    \n",
        "    return bbox_list\n",
        "\n",
        "def createDataset(images, labels, batch_size, dim):\n",
        "    # Making dataset and dataloaders for PyTorch from a set of image filenames and labels.\n",
        "    dataset = MyDataset(images ,labels, dim)\n",
        "    loader = DataLoader(dataset,batch_size=batch_size, shuffle=False)\n",
        "    return dataset, loader\n",
        "\n",
        "def readTrImages(batch_size, split_ratio, dim=256, shuffle=False, train=False):\n",
        "    # Reading and splitting the images from trainval and returning the dataset objects and the dataloaders for training.\n",
        "    #labels_dict = readTrLabels()\n",
        "    images = []\n",
        "    labels = []\n",
        "    deploy_trainval_dir = deploy_dir + '/deploy/trainval/'\n",
        "\n",
        "    for folder in os.listdir(deploy_trainval_dir):\n",
        "        if folder.endswith(\".csv\"):\n",
        "            continue\n",
        "        for file in os.listdir(deploy_trainval_dir + folder):\n",
        "            if file.endswith(\"_image.jpg\"):\n",
        "                image_id = folder + \"/\" + file[:-10]\n",
        "                #tmp_label = labels_dict[image_id]\n",
        "                tmp_fn = deploy_trainval_dir + folder + \"/\" + file\n",
        "                images.append(tmp_fn)\n",
        "                #labels.append(tmp_label)\n",
        "                bbox_list = readBbox(tmp_fn)\n",
        "                labels.append(bbox_list)\n",
        "                                             \n",
        "\n",
        "    print(str(len(images)) + \" images read.\")\n",
        "    print(str(len(labels)) + \" labels read.\")\n",
        "    idx_shuffled = list(range(0, len(images)))\n",
        "\n",
        "    if shuffle:\n",
        "        random.shuffle(idx_shuffled)\n",
        "\n",
        "    split_idx = int(split_ratio * len(images))\n",
        "    train_images = [images[i] for i in idx_shuffled[:split_idx]]\n",
        "    train_labels = [labels[i] for i in idx_shuffled[:split_idx]]\n",
        "    val_images = [images[i] for i in idx_shuffled[split_idx:]]\n",
        "    val_labels = [labels[i] for i in idx_shuffled[split_idx:]]\n",
        "\n",
        "    train_dataset, train_loader = createDataset(train_images, train_labels, batch_size, dim)\n",
        "\n",
        "    val_dataset, val_loader = createDataset(val_images, val_labels, batch_size, dim)\n",
        "    print(\"Dataloaders created, train has \" + str(len(train_dataset)) + \" samples and val has \" + str(len(val_dataset)) + \" samples.\")\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HrnDDSohFqe"
      },
      "source": [
        "Model Training Code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9sWg3tWvzar",
        "outputId": "da524709-bc8d-47b3-bf02-0e693e621349"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\Alex/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:02<00:00, 39.2MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 128, 128]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
            "              ReLU-3         [-1, 64, 128, 128]               0\n",
            "         MaxPool2d-4           [-1, 64, 64, 64]               0\n",
            "            Conv2d-5           [-1, 64, 64, 64]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 64, 64]             128\n",
            "              ReLU-7           [-1, 64, 64, 64]               0\n",
            "            Conv2d-8           [-1, 64, 64, 64]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 64, 64]             128\n",
            "             ReLU-10           [-1, 64, 64, 64]               0\n",
            "           Conv2d-11          [-1, 256, 64, 64]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 64, 64]             512\n",
            "           Conv2d-13          [-1, 256, 64, 64]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 64, 64]             512\n",
            "             ReLU-15          [-1, 256, 64, 64]               0\n",
            "       Bottleneck-16          [-1, 256, 64, 64]               0\n",
            "           Conv2d-17           [-1, 64, 64, 64]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 64, 64]             128\n",
            "             ReLU-19           [-1, 64, 64, 64]               0\n",
            "           Conv2d-20           [-1, 64, 64, 64]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 64, 64]             128\n",
            "             ReLU-22           [-1, 64, 64, 64]               0\n",
            "           Conv2d-23          [-1, 256, 64, 64]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 64, 64]             512\n",
            "             ReLU-25          [-1, 256, 64, 64]               0\n",
            "       Bottleneck-26          [-1, 256, 64, 64]               0\n",
            "           Conv2d-27           [-1, 64, 64, 64]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 64, 64]             128\n",
            "             ReLU-29           [-1, 64, 64, 64]               0\n",
            "           Conv2d-30           [-1, 64, 64, 64]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 64, 64]             128\n",
            "             ReLU-32           [-1, 64, 64, 64]               0\n",
            "           Conv2d-33          [-1, 256, 64, 64]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 64, 64]             512\n",
            "             ReLU-35          [-1, 256, 64, 64]               0\n",
            "       Bottleneck-36          [-1, 256, 64, 64]               0\n",
            "           Conv2d-37          [-1, 128, 64, 64]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 64, 64]             256\n",
            "             ReLU-39          [-1, 128, 64, 64]               0\n",
            "           Conv2d-40          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 32, 32]             256\n",
            "             ReLU-42          [-1, 128, 32, 32]               0\n",
            "           Conv2d-43          [-1, 512, 32, 32]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 32, 32]           1,024\n",
            "           Conv2d-45          [-1, 512, 32, 32]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-47          [-1, 512, 32, 32]               0\n",
            "       Bottleneck-48          [-1, 512, 32, 32]               0\n",
            "           Conv2d-49          [-1, 128, 32, 32]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 32, 32]             256\n",
            "             ReLU-51          [-1, 128, 32, 32]               0\n",
            "           Conv2d-52          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 32, 32]             256\n",
            "             ReLU-54          [-1, 128, 32, 32]               0\n",
            "           Conv2d-55          [-1, 512, 32, 32]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-57          [-1, 512, 32, 32]               0\n",
            "       Bottleneck-58          [-1, 512, 32, 32]               0\n",
            "           Conv2d-59          [-1, 128, 32, 32]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 32, 32]             256\n",
            "             ReLU-61          [-1, 128, 32, 32]               0\n",
            "           Conv2d-62          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 32, 32]             256\n",
            "             ReLU-64          [-1, 128, 32, 32]               0\n",
            "           Conv2d-65          [-1, 512, 32, 32]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-67          [-1, 512, 32, 32]               0\n",
            "       Bottleneck-68          [-1, 512, 32, 32]               0\n",
            "           Conv2d-69          [-1, 128, 32, 32]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 32, 32]             256\n",
            "             ReLU-71          [-1, 128, 32, 32]               0\n",
            "           Conv2d-72          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 32, 32]             256\n",
            "             ReLU-74          [-1, 128, 32, 32]               0\n",
            "           Conv2d-75          [-1, 512, 32, 32]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-77          [-1, 512, 32, 32]               0\n",
            "       Bottleneck-78          [-1, 512, 32, 32]               0\n",
            "           Conv2d-79          [-1, 256, 32, 32]         131,072\n",
            "      BatchNorm2d-80          [-1, 256, 32, 32]             512\n",
            "             ReLU-81          [-1, 256, 32, 32]               0\n",
            "           Conv2d-82          [-1, 256, 16, 16]         589,824\n",
            "      BatchNorm2d-83          [-1, 256, 16, 16]             512\n",
            "             ReLU-84          [-1, 256, 16, 16]               0\n",
            "           Conv2d-85         [-1, 1024, 16, 16]         262,144\n",
            "      BatchNorm2d-86         [-1, 1024, 16, 16]           2,048\n",
            "           Conv2d-87         [-1, 1024, 16, 16]         524,288\n",
            "      BatchNorm2d-88         [-1, 1024, 16, 16]           2,048\n",
            "             ReLU-89         [-1, 1024, 16, 16]               0\n",
            "       Bottleneck-90         [-1, 1024, 16, 16]               0\n",
            "           Conv2d-91          [-1, 256, 16, 16]         262,144\n",
            "      BatchNorm2d-92          [-1, 256, 16, 16]             512\n",
            "             ReLU-93          [-1, 256, 16, 16]               0\n",
            "           Conv2d-94          [-1, 256, 16, 16]         589,824\n",
            "      BatchNorm2d-95          [-1, 256, 16, 16]             512\n",
            "             ReLU-96          [-1, 256, 16, 16]               0\n",
            "           Conv2d-97         [-1, 1024, 16, 16]         262,144\n",
            "      BatchNorm2d-98         [-1, 1024, 16, 16]           2,048\n",
            "             ReLU-99         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-100         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-101          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-102          [-1, 256, 16, 16]             512\n",
            "            ReLU-103          [-1, 256, 16, 16]               0\n",
            "          Conv2d-104          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-105          [-1, 256, 16, 16]             512\n",
            "            ReLU-106          [-1, 256, 16, 16]               0\n",
            "          Conv2d-107         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-108         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-109         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-110         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-111          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-112          [-1, 256, 16, 16]             512\n",
            "            ReLU-113          [-1, 256, 16, 16]               0\n",
            "          Conv2d-114          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-115          [-1, 256, 16, 16]             512\n",
            "            ReLU-116          [-1, 256, 16, 16]               0\n",
            "          Conv2d-117         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-118         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-119         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-120         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-121          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-122          [-1, 256, 16, 16]             512\n",
            "            ReLU-123          [-1, 256, 16, 16]               0\n",
            "          Conv2d-124          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-125          [-1, 256, 16, 16]             512\n",
            "            ReLU-126          [-1, 256, 16, 16]               0\n",
            "          Conv2d-127         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-128         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-129         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-130         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-131          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 16, 16]             512\n",
            "            ReLU-133          [-1, 256, 16, 16]               0\n",
            "          Conv2d-134          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 16, 16]             512\n",
            "            ReLU-136          [-1, 256, 16, 16]               0\n",
            "          Conv2d-137         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-139         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-140         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-141          [-1, 512, 16, 16]         524,288\n",
            "     BatchNorm2d-142          [-1, 512, 16, 16]           1,024\n",
            "            ReLU-143          [-1, 512, 16, 16]               0\n",
            "          Conv2d-144            [-1, 512, 8, 8]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-146            [-1, 512, 8, 8]               0\n",
            "          Conv2d-147           [-1, 2048, 8, 8]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 8, 8]           4,096\n",
            "          Conv2d-149           [-1, 2048, 8, 8]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-151           [-1, 2048, 8, 8]               0\n",
            "      Bottleneck-152           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-153            [-1, 512, 8, 8]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-155            [-1, 512, 8, 8]               0\n",
            "          Conv2d-156            [-1, 512, 8, 8]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-158            [-1, 512, 8, 8]               0\n",
            "          Conv2d-159           [-1, 2048, 8, 8]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-161           [-1, 2048, 8, 8]               0\n",
            "      Bottleneck-162           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-163            [-1, 512, 8, 8]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-165            [-1, 512, 8, 8]               0\n",
            "          Conv2d-166            [-1, 512, 8, 8]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-168            [-1, 512, 8, 8]               0\n",
            "          Conv2d-169           [-1, 2048, 8, 8]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-171           [-1, 2048, 8, 8]               0\n",
            "      Bottleneck-172           [-1, 2048, 8, 8]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "        Identity-174                 [-1, 2048]               0\n",
            "          ResNet-175                 [-1, 2048]               0\n",
            "          Linear-176                  [-1, 128]         262,272\n",
            "            ReLU-177                  [-1, 128]               0\n",
            "          Linear-178                   [-1, 64]           8,256\n",
            "            ReLU-179                   [-1, 64]               0\n",
            "          Linear-180                   [-1, 32]           2,080\n",
            "            ReLU-181                   [-1, 32]               0\n",
            "          Linear-182                    [-1, 4]             132\n",
            "         Sigmoid-183                    [-1, 4]               0\n",
            "          Linear-184                  [-1, 512]       1,049,088\n",
            "            ReLU-185                  [-1, 512]               0\n",
            "         Dropout-186                  [-1, 512]               0\n",
            "          Linear-187                  [-1, 512]         262,656\n",
            "            ReLU-188                  [-1, 512]               0\n",
            "         Dropout-189                  [-1, 512]               0\n",
            "          Linear-190                    [-1, 3]           1,539\n",
            "================================================================\n",
            "Total params: 25,094,055\n",
            "Trainable params: 25,094,055\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 374.32\n",
            "Params size (MB): 95.73\n",
            "Estimated Total Size (MB): 470.80\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# import the necessary packages\n",
        "import sys\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "from torch.nn import Dropout\n",
        "from torch.nn import Identity\n",
        "from torch.nn import Linear\n",
        "from torch.nn import Module\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import Sequential\n",
        "from torch.nn import Sigmoid\n",
        "\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from torchvision.models import resnet50\n",
        "\n",
        "class Model(Module):\n",
        "\tdef __init__(self, baseModel, numClasses, in_features=2048):\n",
        "\t\tsuper(Model, self).__init__()\n",
        "\t\t# initialize the base model and the number of classes\n",
        "\t\tself.baseModel = resnet50(pretrained=True)\n",
        "\t\tself.numClasses = numClasses\n",
        "    # build the regressor head for outputting the bounding box\n",
        "\t\t# coordinates\n",
        "\t\tself.regressor = Sequential(\n",
        "\t\t\tLinear(in_features, 128),\n",
        "\t\t\tReLU(),\n",
        "\t\t\tLinear(128, 64),\n",
        "\t\t\tReLU(),\n",
        "\t\t\tLinear(64, 32),\n",
        "\t\t\tReLU(),\n",
        "\t\t\tLinear(32, 4),\n",
        "\t\t\tSigmoid()\n",
        "\t\t)\n",
        "    # build the classifier head to predict the class labels\n",
        "\t\tself.classifier = Sequential(\n",
        "\t\t\tLinear(in_features, 512),\n",
        "\t\t\tReLU(),\n",
        "\t\t\tDropout(),\n",
        "\t\t\tLinear(512, 512),\n",
        "\t\t\tReLU(),\n",
        "\t\t\tDropout(),\n",
        "\t\t\tLinear(512, self.numClasses)\n",
        "\t\t)\n",
        "\t\t# set the classifier of our base model to produce outputs\n",
        "\t\t# from the last convolution block\n",
        "\t\tself.baseModel.fc = Identity()\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\t# pass the inputs through the base model and then obtain\n",
        "\t\t# predictions from two different branches of the network\n",
        "\t\tfeatures = self.baseModel(x)\n",
        "\t\tbboxes = self.regressor(features)\n",
        "\t\tclassLogits = self.classifier(features)\n",
        "\t\tclassLogits = F.softmax(classLogits, dim=1)\n",
        "\t\t# return the outputs as a tuple\n",
        "\t\treturn (bboxes, classLogits)\n",
        "  \n",
        "from torchsummary import summary\n",
        "resnet = resnet50(pretrained=True)\n",
        "model = Model(resnet50(pretrained=True), 3, 2048)\n",
        "model = model.to(device=device)\n",
        "summary(model, (3, 256, 256))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htcG1_y7hJoY",
        "outputId": "7a59ef18-48be-4b72-a1ad-d3630878505b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (baseModel): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Identity()\n",
            "  )\n",
            "  (regressor): Sequential(\n",
            "    (0): Linear(in_features=2048, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=32, out_features=4, bias=True)\n",
            "    (7): Sigmoid()\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=512, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-4-b222066f5dd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreadTrImages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjectDetector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-2-e246e6466d7d>\u001b[0m in \u001b[0;36mreadTrImages\u001b[1;34m(batch_size, split_ratio, dim, shuffle, train)\u001b[0m\n\u001b[0;32m    248\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m                 \u001b[1;31m#labels.append(tmp_label)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m                 \u001b[0mbbox_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreadBbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m                 \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbbox_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-2-e246e6466d7d>\u001b[0m in \u001b[0;36mreadBbox\u001b[1;34m(snapshot)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mreadBbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msnapshot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m     \u001b[0mxyz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msnapshot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_image.jpg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cloud.bin'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m     \u001b[0mxyz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxyz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "resnet = resnet50(pretrained=True)\n",
        "# freeze all ResNet50 layers so they will *not* be updated during the\n",
        "# training process\n",
        "for param in resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# create our custom object detector model and flash it to the current\n",
        "# device\n",
        "objectDetector = Model(resnet50, 3)\n",
        "objectDetector = objectDetector.to(device=device)\n",
        "# define our loss functions\n",
        "classLossFunc = CrossEntropyLoss()\n",
        "bboxLossFunc = MSELoss()\n",
        "# initialize the optimizer, compile the model, and show the model\n",
        "# summary\n",
        "# print(objectDetector)\n",
        "# initialize a dictionary to store training history\n",
        "H = {\"total_train_loss\": [], \"total_val_loss\": [], \"train_class_acc\": [],\"val_class_acc\": []}\n",
        "  \n",
        "\n",
        "def train(model, train_loader, val_loader, num_epochs):\n",
        "    classLossFunc = torch.nn.BCELoss()\n",
        "    bboxLossFunc = MSELoss()\n",
        "    lr = 1e-4\n",
        "    optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
        "    start_epoch = 0\n",
        "    \n",
        "    num_iters = len(train_loader)\n",
        "\n",
        "    for epoch in range(start_epoch, num_epochs):  # loop over the dataset multiple times  \n",
        "        print(\"Training epoch: \" + str(epoch) + \" of \" + str(num_epochs))\n",
        "        totalTrainLoss = 0\n",
        "        totalValLoss = 0\n",
        "        # initialize the number of correct predictions in the training\n",
        "        # and validation step\n",
        "        trainCorrect = 0\n",
        "        valCorrect = 0\n",
        "        model.train()\n",
        "        for i, data in enumerate(train_loader):\n",
        "            # get the inputs; data is a list of [batch, labels]\n",
        "            print(\"Started Iteration: \" + str(i) + \" of \" + str(num_iters))\n",
        "            batch, targets = data\n",
        "            bboxes = targets[\"boxes\"]\n",
        "            labels = targets[\"labels\"]\n",
        "            bboxes = bboxes.type(torch.float)\n",
        "            labels = labels.type(torch.float)\n",
        "            predictions = model(batch)\n",
        "            bboxLoss = bboxLossFunc(predictions[0], bboxes)\n",
        "            classLoss = classLossFunc(predictions[1], labels.float())\n",
        "            totalLoss = (1 * bboxLoss) + (1 * classLoss)\n",
        "            optimizer.zero_grad()\n",
        "            totalLoss.backward()\n",
        "            print(\"Backward done on this iteration, learning rate - \", lr)\n",
        "            optimizer.step()\n",
        "            print(\"Model finished running iteration\", i, \"\\n\")\n",
        "            print(\"Loss:\", totalLoss)\n",
        "            print(\"Running Loss:\", totalTrainLoss)\n",
        "            totalTrainLoss += totalLoss\n",
        "            trainCorrect += (predictions[1].argmax(1) == labels.argmax(1)).type(torch.float).sum().item()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # set the model in evaluation mode\n",
        "            model.eval()\n",
        "            # loop over the validation set\n",
        "            for i, data in enumerate(val_loader):\n",
        "              # get the inputs; data is a list of [batch, labels]\n",
        "              print(\"Started Iteration: \" + str(i) + \" of \" + str(num_iters))\n",
        "              batch, targets = data\n",
        "              bboxes = targets[\"boxes\"]\n",
        "              labels = targets[\"labels\"]\n",
        "              bboxes = bboxes.type(torch.float)\n",
        "              labels = labels.type(torch.float)\n",
        "              predictions = model(batch)\n",
        "              bboxLoss = bboxLossFunc(predictions[0], bboxes)\n",
        "              classLoss = classLossFunc(predictions[1], labels.float())\n",
        "              totalLoss = (1 * bboxLoss) + (1 * classLoss)\n",
        "              totalValLoss += totalLoss\n",
        "\n",
        "              # calculate the number of correct predictions\n",
        "              valCorrect += (predictions[1].argmax(1) == labels).type(torch.float).sum().item()\n",
        "        \t# calculate the average training and validation loss\n",
        "\n",
        "        avgTrainLoss = totalTrainLoss / trainSteps\n",
        "        avgValLoss = totalValLoss / valSteps\n",
        "        # calculate the training and validation accuracy\n",
        "        trainCorrect = trainCorrect / len(train_loader)\n",
        "        valCorrect = valCorrect / len(val_loader)\n",
        "        # update our training history\n",
        "        H[\"total_train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
        "        H[\"train_class_acc\"].append(trainCorrect)\n",
        "        H[\"total_val_loss\"].append(avgValLoss.cpu().detach().numpy())\n",
        "        H[\"val_class_acc\"].append(valCorrect)\n",
        "        # print the model training and validation information\n",
        "        print(\"[INFO] EPOCH: {}/{}\".format(epoch + 1, num_epochs))\n",
        "        print(\"Train loss: {:.6f}, Train accuracy: {:.4f}\".format(avgTrainLoss, trainCorrect))\n",
        "        print(\"Val loss: {:.6f}, Val accuracy: {:.4f}\".format(avgValLoss, valCorrect))  \n",
        "\n",
        "        \n",
        "        model_fn = model_save_dir + \"/model_epoch\" + str(epoch) + \"_loss\" + str(avgTrainLoss) + \"_vacc\" + str(valCorrect) + \".pt\"\n",
        "        torch.save({\n",
        "        'epoch': (epoch+1),\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': avgTrainLoss,\n",
        "        'vacc': valCorrect\n",
        "        }, model_fn)\n",
        "\n",
        "\n",
        "    print('Finished Training')\n",
        "    return model, H\n",
        "\n",
        "train_loader, val_loader = readTrImages(4, 0.7, dim=400)\n",
        "torch.cuda.empty_cache()\n",
        "model = train(objectDetector, train_loader, val_loader, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4q5o6xtuiF9"
      },
      "source": [
        "Testing and output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdI2apWJtpbx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "\n",
        "def runModel(model, img_fn, dim):\n",
        "    image = Image.open(img_fn)\n",
        "    image = image.resize((dim, dim))\n",
        "    convert_tensor = transforms.ToTensor()\n",
        "    x = convert_tensor(image)\n",
        "    x = torch.stack([x])\n",
        "    x = x.float()\n",
        "    outputs = model(x)\n",
        "    y = torch.argmax(outputs[1], dim=1).item()\n",
        "    return y\n",
        "\n",
        "def writeSubmission(model, dim=224):\n",
        "    # The code for the submission after running the model.\n",
        "    output = open(model_save_dir + '/Team19.txt', 'w')\n",
        "    output.write('guid/image,label\\n')\n",
        "    count = 0\n",
        "\n",
        "    for folder in os.listdir(deploy_dir +'/deploy/test/'):\n",
        "        for file in os.listdir(deploy_dir + '/deploy/test/' + folder):\n",
        "            if file.endswith(\"_image.jpg\"):\n",
        "                tmp_fn = deploy_dir + '/deploy/test/' + folder + \"/\" + file\n",
        "                out_label = runModel(model, tmp_fn, dim)\n",
        "                output.write(folder + \"/\" + file[:-10] + \",\" + str(out_label) + \"\\n\")\n",
        "                count += 1\n",
        "\n",
        "    print(count)\n",
        "    output.close()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Perception-Rob 535 Team 19 Fall 21.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
